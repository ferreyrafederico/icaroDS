{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f241a42",
   "metadata": {},
   "source": [
    "# Descargar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c26615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descargar siempre cuando usen Colab\n",
    "#!pip install praw tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea947862",
   "metadata": {},
   "source": [
    "# Iniciar el Extractor y Completar debajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f4d9ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recopilando publicaciones: 968it [28:39,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han extraído y guardado exitosamente 851 publicaciones nuevas del subreddit 'argentina'.\n",
      "Proceso finalizado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configura tu instancia de PRAW con tus credenciales de la aplicación y un user_agent único\n",
    "reddit_config = {\n",
    "    'client_id': '9zK4SSfBSCMJPnpX1rbg4Q',\n",
    "    'client_secret': 'CI5_-mXS5NGVZMvNjmOb6kyE60fG_A',\n",
    "    'user_agent': 'MiScriptRedditBot/v1.7 (by Sheincito en Reddit)'\n",
    "}\n",
    "\n",
    "# Define el subreddit a extraer\n",
    "subreddit_to_extract = input(\"Ingrese el nombre del subreddit: \")\n",
    "\n",
    "# Define el filtro para los títulos de las publicaciones\n",
    "filtro_titulo = input(\"Ingrese el filtro para los títulos de las publicaciones (deje en blanco para no filtrar por título): \")\n",
    "\n",
    "# Define el filtro para el cuerpo de las publicaciones\n",
    "filtro_cuerpo = input(\"Ingrese el filtro para el cuerpo de las publicaciones (deje en blanco para no filtrar por cuerpo): \")\n",
    "\n",
    "# Nombre del archivo CSV basado en el subreddit extraído\n",
    "csv_filename = f\"extractor_{subreddit_to_extract}.csv\"\n",
    "\n",
    "# Función para cargar los títulos existentes del archivo CSV\n",
    "def cargar_titulos_existentes(filename, subreddit_name):\n",
    "    if os.path.isfile(filename):  \n",
    "        try:\n",
    "            df = pd.read_csv(filename)\n",
    "            if df.empty:\n",
    "                return df\n",
    "            else:\n",
    "                return set(df['Reddit'])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            return df\n",
    "    else: \n",
    "        return pd.DataFrame(columns=[subreddit_name])\n",
    "\n",
    "# Función para recopilar publicaciones\n",
    "def recopilar_publicaciones(subreddit_name, filename, reddit, filtro_titulo=None, filtro_cuerpo=None):\n",
    "    # Cargar los títulos existentes del archivo CSV\n",
    "    titulos_existentes = cargar_titulos_existentes(filename, subreddit_name)\n",
    "    \n",
    "    # Obtiene el subreddit\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    \n",
    "    # Lista para almacenar las publicaciones\n",
    "    posts = []\n",
    "    \n",
    "    # Convertir el filtro de título a minúsculas si está presente\n",
    "    filtro_titulo = filtro_titulo.lower() if filtro_titulo else None\n",
    "    \n",
    "    # Convertir el filtro de cuerpo a minúsculas si está presente\n",
    "    filtro_cuerpo = filtro_cuerpo.lower() if filtro_cuerpo else None\n",
    "    \n",
    "    # Dividir el filtro de título en palabras si contiene varias palabras\n",
    "    filtro_titulo_palabras = filtro_titulo.split() if filtro_titulo else None\n",
    "    \n",
    "    # Dividir el filtro de cuerpo en palabras si contiene varias palabras\n",
    "    filtro_cuerpo_palabras = filtro_cuerpo.split() if filtro_cuerpo else None\n",
    "    \n",
    "    # Bucle para recopilar publicaciones\n",
    "    for submission in tqdm(subreddit.new(limit=None), desc='Recopilando publicaciones'):\n",
    "        # Convertir el título y el cuerpo a minúsculas para comparación sin distinción de mayúsculas y minúsculas\n",
    "        titulo_lower = submission.title.lower()\n",
    "        cuerpo_lower = submission.selftext.lower()\n",
    "        \n",
    "        # Verificar si la publicación cumple con al menos uno de los filtros\n",
    "        if (not filtro_titulo or any(word in titulo_lower for word in filtro_titulo_palabras)) \\\n",
    "            or (not filtro_cuerpo or any(word in cuerpo_lower for word in filtro_cuerpo_palabras)):\n",
    "            \n",
    "            # Verifica si el título de la publicación ya está en los títulos existentes\n",
    "            if submission.title not in titulos_existentes:\n",
    "                # Agrega el título a la lista de títulos y al conjunto de títulos existentes\n",
    "                titulos_existentes.add(submission.title)\n",
    "\n",
    "                # Agrega el título y el cuerpo de la publicación a la lista de publicaciones\n",
    "                posts.append({'Reddit': submission.title, 'Body': submission.selftext})\n",
    "\n",
    "                # Espera 2 segundos antes de procesar la siguiente publicación\n",
    "                time.sleep(2)\n",
    "    \n",
    "    # Convierte la lista de publicaciones en un DataFrame\n",
    "    df = pd.DataFrame(posts)\n",
    "    \n",
    "    # Guarda las publicaciones en un archivo CSV (modo 'a' para agregar datos sin sobrescribir)\n",
    "    df.to_csv(filename, index=False, mode='a', header=not os.path.exists(filename))\n",
    "    \n",
    "    # Mensaje de finalización\n",
    "    print(f\"Se han extraído y guardado exitosamente {len(posts)} publicaciones nuevas del subreddit '{subreddit_name}'.\")\n",
    "    print(\"Proceso finalizado.\")\n",
    "\n",
    "# Configura PRAW con la configuración especificada\n",
    "reddit = praw.Reddit(**reddit_config)\n",
    "\n",
    "# Llama a la función para recopilar publicaciones y guardarlas en un archivo CSV\n",
    "recopilar_publicaciones(subreddit_to_extract, csv_filename, reddit, filtro_titulo, filtro_cuerpo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9315eb18",
   "metadata": {},
   "source": [
    "# Cargamos el DF generado para probar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368b06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el archivo CSV que contiene los datos del DataFrame\n",
    "df = pd.read_csv(csv_filename)\n",
    "pd.options.display.max_colwidth = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b508e449",
   "metadata": {},
   "source": [
    "## Aqui borre los nulos por que cuando hay imagenes no las guarda y queda como NaN en el Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc622327",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.dropna(subset=['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caad84cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b083b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2['Reddit'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e6d74fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Oficial: Derogacion inmediata del articulo que sube sueldos a Presidencia y compañia. Milei se baja el sueldo.</td>\n",
       "      <td>Fuente: https://twitter.com/madorni/status/1766652989341610397?t=qSVxwOcYfV_7doV-PozJGg&amp;s=19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Oficial: Derogacion inmediata del articulo que sube sueldos a Presidencia y compañia. Milei se baja el sueldo.</td>\n",
       "      <td>Fuente: https://twitter.com/madorni/status/1766652989341610397?t=qSVxwOcYfV_7doV-PozJGg&amp;s=19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Oficial: Derogacion inmediata del articulo que sube sueldos a Presidencia y compañia. Milei se baja el sueldo.</td>\n",
       "      <td>Fuente: https://twitter.com/madorni/status/1766652989341610397?t=qSVxwOcYfV_7doV-PozJGg&amp;s=19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Oficial: Derogacion inmediata del articulo que sube sueldos a Presidencia y compañia. Milei se baja el sueldo.</td>\n",
       "      <td>Fuente: https://twitter.com/madorni/status/1766652989341610397?t=qSVxwOcYfV_7doV-PozJGg&amp;s=19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Oficial: Derogacion inmediata del articulo que sube sueldos a Presidencia y compañia. Milei se baja el sueldo.</td>\n",
       "      <td>Fuente: https://twitter.com/madorni/status/1766652989341610397?t=qSVxwOcYfV_7doV-PozJGg&amp;s=19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                             Reddit  \\\n",
       "54   Oficial: Derogacion inmediata del articulo que sube sueldos a Presidencia y compañia. Milei se baja el sueldo.   \n",
       "64   Oficial: Derogacion inmediata del articulo que sube sueldos a Presidencia y compañia. Milei se baja el sueldo.   \n",
       "75   Oficial: Derogacion inmediata del articulo que sube sueldos a Presidencia y compañia. Milei se baja el sueldo.   \n",
       "87   Oficial: Derogacion inmediata del articulo que sube sueldos a Presidencia y compañia. Milei se baja el sueldo.   \n",
       "100  Oficial: Derogacion inmediata del articulo que sube sueldos a Presidencia y compañia. Milei se baja el sueldo.   \n",
       "\n",
       "                                                                                             Body  \n",
       "54   Fuente: https://twitter.com/madorni/status/1766652989341610397?t=qSVxwOcYfV_7doV-PozJGg&s=19  \n",
       "64   Fuente: https://twitter.com/madorni/status/1766652989341610397?t=qSVxwOcYfV_7doV-PozJGg&s=19  \n",
       "75   Fuente: https://twitter.com/madorni/status/1766652989341610397?t=qSVxwOcYfV_7doV-PozJGg&s=19  \n",
       "87   Fuente: https://twitter.com/madorni/status/1766652989341610397?t=qSVxwOcYfV_7doV-PozJGg&s=19  \n",
       "100  Fuente: https://twitter.com/madorni/status/1766652989341610397?t=qSVxwOcYfV_7doV-PozJGg&s=19  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c31111de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una máscara booleana para las filas que contienen la palabra \"milei\" en el título o el texto\n",
    "mask = df2['Reddit'].str.contains('milei', case=False) | df2['Body'].str.contains('milei', case=False)\n",
    "\n",
    "# Aplicar la máscara para filtrar las filas\n",
    "df_f = df2[mask]\n",
    "\n",
    "df_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aedefb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una máscara booleana para las filas que contienen la palabra \"milei\" en el título o el texto\n",
    "mask = ~(df2['Reddit'].str.contains('milei', case=False) | df2['Body'].str.contains('milei', case=False))\n",
    "\n",
    "# Aplicar la máscara para filtrar las filas\n",
    "df_p = df2[mask]\n",
    "\n",
    "df_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "badc4b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reddit</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6115</th>\n",
       "      <td>Virgen a los 40...</td>\n",
       "      <td>Tengo 25, nunca he tenido pareja/novia nada serio . Estoy pensando en desvivirme. (Y no . No soy virgen de sexo. Ya me cansé del amor pago) busco algo más quiero una compañera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>Amenazaron en vivo a Nelson Castro en Rosario mientras cubría nota en TN</td>\n",
       "      <td>Estaba hablando y justo le enviaron un mensaje amenazandolo de muerte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>Vivo en Rosario, hagan sus preguntas...</td>\n",
       "      <td>Bueno , veo que muchos tienen dudas de como es vivir en Rosario.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>Lunes Random</td>\n",
       "      <td>Cosas Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6129</th>\n",
       "      <td>Thread Diario de Dudas, Consultas y Mitaps - 11/03</td>\n",
       "      <td>Thread Diario de Dudas y Consultas!\\n\\nEntra a nuestro [Discord](https://discord.gg/PeaSPMPn46) y charla con la comunidad!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         Reddit  \\\n",
       "6115                                                         Virgen a los 40...   \n",
       "6121  Amenazaron en vivo a Nelson Castro en Rosario mientras cubría nota en TN    \n",
       "6127                                    Vivo en Rosario, hagan sus preguntas...   \n",
       "6128                                                               Lunes Random   \n",
       "6129                         Thread Diario de Dudas, Consultas y Mitaps - 11/03   \n",
       "\n",
       "                                                                                                                                                                                  Body  \n",
       "6115  Tengo 25, nunca he tenido pareja/novia nada serio . Estoy pensando en desvivirme. (Y no . No soy virgen de sexo. Ya me cansé del amor pago) busco algo más quiero una compañera   \n",
       "6121                                                                                                            Estaba hablando y justo le enviaron un mensaje amenazandolo de muerte   \n",
       "6127                                                                                                                  Bueno , veo que muchos tienen dudas de como es vivir en Rosario.  \n",
       "6128                                                                                                                                                                      Cosas Random  \n",
       "6129                                                        Thread Diario de Dudas y Consultas!\\n\\nEntra a nuestro [Discord](https://discord.gg/PeaSPMPn46) y charla con la comunidad!  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f983ef01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_f['Reddit'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
